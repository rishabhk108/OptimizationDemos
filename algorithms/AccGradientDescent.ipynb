{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Lets Load the dataset. We shall use the following datasets:\n",
    "Features are in: \"sido0_train.mat\"\n",
    "Labels are in: \"sido0_train.targets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12678, 4932)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "X = loadmat(r\"sido0_matlab/sido0_train.mat\")\n",
    "y = np.loadtxt(r\"sido0_matlab/sido0_train.targets\")\n",
    "\n",
    "# Statistics of the Dense Format of X\n",
    "X = X['X'].todense()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Definition\n",
    "Lets use the Logistic Regression definition we previously used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticLoss(w, X, y, lam):\n",
    "    # Computes the cost function for all the training samples\n",
    "    m = X.shape[0]\n",
    "    Xw = np.dot(X,w)\n",
    "    yT = y.reshape(-1,1)\n",
    "    yXw = np.multiply(yT,Xw)\n",
    "    f = np.sum(np.logaddexp(0,-yXw)) + 0.5*lam*np.sum(np.multiply(w,w))\n",
    "    gMul = 1/(1 + np.exp(yXw))\n",
    "    ymul = -1*np.multiply(yT, gMul)\n",
    "    g =  np.dot(ymul.reshape(1,-1),X) + lam*w.reshape(1,-1)\n",
    "    g = g.reshape(-1,1)\n",
    "    return [f, g]      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinvoking Gradient Descent Armiojo V4\n",
    "Lets invoke the final version of Armijo Line Search GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "\n",
    "def gdArmijo(funObj,w,maxEvals,alpha,gamma,X,y,lam, verbosity, freq):\n",
    "    [f,g] = funObj(w,X,y,lam)\n",
    "    funEvals = 1\n",
    "    funVals = []\n",
    "    f_old = f\n",
    "    g_old = g\n",
    "    funVals.append(f)\n",
    "    alpha = 1/LA.norm(g)\n",
    "    numBackTrack = 0\n",
    "    while(1):\n",
    "        wp = w - alpha*g\n",
    "        [fp,gp] = funObj(wp,X,y,lam)\n",
    "        funVals.append(f)\n",
    "        funEvals = funEvals+1\n",
    "        backtrack = 0\n",
    "        while fp > f - gamma*alpha*np.dot(g.T, g):\n",
    "            alpha = alpha*alpha*np.dot(g.T, g)[0,0]/(2*(fp + np.dot(g.T, g)[0,0]*alpha - f))\n",
    "            wp = w - alpha*g\n",
    "            [fp,gp] = funObj(wp,X,y,lam)\n",
    "            funVals.append(f)\n",
    "            funEvals = funEvals+1\n",
    "            numBackTrack = numBackTrack + 1\n",
    "        if funEvals > 2:\n",
    "            alpha = min(1,2*(f_old - f)/np.dot(g.T, g)[0,0])\n",
    "        f_old = f\n",
    "        g_old = g\n",
    "        w = wp\n",
    "        f = fp\n",
    "        g = gp\n",
    "        optCond = LA.norm(g, np.inf)\n",
    "        if ((verbosity > 0) and (funEvals % freq == 0)):\n",
    "            print(funEvals,alpha,f,optCond)\n",
    "        if (optCond < 1e-2):\n",
    "            break\n",
    "        if (funEvals >= maxEvals):\n",
    "            break\n",
    "    return (funVals,numBackTrack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent with Line Search\n",
    "#### Version 1: Armijo Backtracking Line Search\n",
    "Lets now define the most basic version of Gradient Descent and tune the learning rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "\n",
    "def gdAccelerated(funObj,w,maxEvals,alpha,gamma,X,y,lam, verbosity, freq):\n",
    "    [f,g] = funObj(w,X,y,lam)\n",
    "    funEvals = 1\n",
    "    funVals = []\n",
    "    funVals.append(f)\n",
    "    numBackTrack = 0\n",
    "    t = 1; \n",
    "    x = w;\n",
    "    while(1):\n",
    "        if (funEvals > 1):\n",
    "            tp = (1 + np.sqrt(1+4*t*t))/2\n",
    "            x = w + ((t-1)/tp)*(w-w_old)\n",
    "            t = tp\n",
    "            [f,g] = funObj(x,X,y,lam)\n",
    "            funEvals = funEvals+1\n",
    "        w_old = w\n",
    "        wp = x - alpha*g; \n",
    "        [fp,gp] = funObj(wp,X,y,lam)\n",
    "        funEvals = funEvals+1;\n",
    "        backtrack = 0\n",
    "        while fp > f - gamma*alpha*np.dot(g.T, g):\n",
    "            alpha = alpha*alpha*np.dot(g.T, g)[0,0]/(2*(fp + np.dot(g.T, g)[0,0]*alpha - f))\n",
    "            wp = x - alpha*g; \n",
    "            [fp,gp] = funObj(wp,X,y,lam)\n",
    "            funEvals = funEvals+1;  \n",
    "            funVals.append(f)\n",
    "            numBackTrack = numBackTrack + 1\n",
    "            backtrack = 1            \n",
    "        w = wp\n",
    "        f = fp\n",
    "        g = gp\n",
    "        if (backtrack == 0):\n",
    "            funVals.append(f)\n",
    "        optCond = LA.norm(g, np.inf)\n",
    "        if ((verbosity > 0) and (funEvals % freq == 0)):\n",
    "            print(funEvals,alpha,f,optCond)\n",
    "        if (optCond < 1e-2):\n",
    "            break\n",
    "        if (funEvals >= maxEvals):\n",
    "            break\n",
    "    return (funVals,numBackTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 4.1796056076066775e-05 1012.4951823907003 95.53384664247373\n",
      "30 3.997469461451199e-05 953.5753177548778 35.655121235018115\n",
      "40 0.00012388804702371698 885.1699025757175 31.335650768554615\n",
      "50 1.3144239424878223e-05 868.4387633860271 22.72480197211717\n",
      "60 3.19951286344067e-05 846.6514541812807 38.97806992194706\n",
      "70 6.404017174599795e-05 830.1929117099367 42.25847013698607\n",
      "80 0.00011081246239613855 812.8209357043669 24.121207738723843\n",
      "90 3.612908378647803e-05 797.2790559279035 24.85602397608963\n",
      "100 6.343884114915358e-05 785.5404258802879 19.27475140750184\n",
      "110 0.00013841402942537257 769.2091021378449 22.493117400607588\n",
      "120 9.712124304379424e-05 748.6620774703173 17.151002599529306\n",
      "130 0.00023936031789675434 729.0076217026603 17.03859779736474\n",
      "140 1.9406980779655936e-05 692.6012054315212 17.644861089297766\n",
      "150 6.422924249528637e-05 679.7141080649994 15.576008890767799\n",
      "160 2.41322291549794e-05 669.1484547018877 28.44097383399261\n",
      "170 4.8713805178756046e-05 660.6072256831944 14.413102172561631\n",
      "180 1.2529301830671562e-05 653.9827669332112 28.252653890481643\n",
      "190 3.819751677923672e-05 647.1789725869651 13.116702915237225\n",
      "210 0.00026940911215927874 623.2877509167935 12.716496769920353\n",
      "220 5.7479250462785626e-05 610.9093464901916 11.902977748188208\n",
      "230 3.513706007390374e-05 600.7644208674036 12.009462306254827\n",
      "240 1.002861071551496e-05 592.4282743265723 14.492333059911735\n",
      "250 4.002863754206335e-05 585.1233740802434 21.94867365796802\n",
      "250\n",
      "Number of Backtrackings = 35\n"
     ]
    }
   ],
   "source": [
    "[nSamples,nVars] = X.shape\n",
    "w = np.zeros((nVars,1))\n",
    "(funV1,numBackTrack) = gdArmijo(LogisticLoss,w,250,1,1e-4,X,y,1,1,10)\n",
    "print(len(funV1))\n",
    "print(\"Number of Backtrackings = \" + str(numBackTrack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 1.2270551792159088e-05 3421.4772580811746 447.0919884294048\n",
      "30 1.2270551792159088e-05 1139.9065594799376 80.13019693661147\n",
      "40 1.2270551792159088e-05 1047.8904744907043 54.85223246465415\n",
      "50 1.2270551792159088e-05 985.291868887159 35.03866383246867\n",
      "60 1.2270551792159088e-05 938.086984407997 27.327323327228356\n",
      "70 1.2270551792159088e-05 897.1309162835348 23.599128324252504\n",
      "80 1.2270551792159088e-05 858.3135600342138 21.437055141153905\n",
      "90 1.2270551792159088e-05 820.5533876518972 19.893967924792296\n",
      "100 1.2270551792159088e-05 783.6170359264083 18.610368547231452\n",
      "110 1.2270551792159088e-05 747.8221226783364 17.440211008769058\n",
      "120 1.2270551792159088e-05 713.306991704953 16.288372031217055\n",
      "130 1.2270551792159088e-05 679.9772013181196 15.032861232889823\n",
      "140 1.2270551792159088e-05 647.823562879202 13.553023797030034\n",
      "150 1.2270551792159088e-05 616.9347270841175 11.939031480531353\n",
      "160 1.2270551792159088e-05 587.3827686140373 11.061990453498689\n",
      "170 1.2270551792159088e-05 559.161359353416 10.280160464064606\n",
      "180 1.2270551792159088e-05 532.2136615719661 9.59112748859084\n",
      "190 1.2270551792159088e-05 506.4926368373115 8.9720849813705\n",
      "200 1.2270551792159088e-05 481.9761100536828 8.411442672938987\n",
      "210 1.2270551792159088e-05 458.6449002739151 7.912043009677313\n",
      "220 1.2270551792159088e-05 436.4684377305792 7.476681133777766\n",
      "230 1.2270551792159088e-05 415.40720705430977 7.098858815334528\n",
      "240 1.2270551792159088e-05 395.42003424408847 6.765661390083761\n",
      "250 1.2270551792159088e-05 376.46858369911143 6.464900701773227\n",
      "132\n",
      "Number of Backtrackings = 14\n"
     ]
    }
   ],
   "source": [
    "[nSamples,nVars] = X.shape\n",
    "w = np.zeros((nVars,1))\n",
    "(funV2,numBackTrack) = gdAccelerated(LogisticLoss,w,250,1,1e-4,X,y,1,1,10)\n",
    "print(len(funV2))\n",
    "print(\"Number of Backtrackings = \" + str(numBackTrack))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
